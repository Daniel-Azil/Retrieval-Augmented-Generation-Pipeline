Barak Gahtan1
, Robert J. Shahla1
, Reuven Cohen1
, Alex M. Bronstein1
1Technion Israel Institute of Technology, Haifa, Israel
{barakgahtan, shahlarobert, rcohen, bron}@cs.technion.ac.il
ABSTRACT
QUIC, a new and increasingly used transport protocol, enhances TCP by providing better security,
performance, and features like stream multiplexing. These features, however, also impose challenges
for network middle-boxes that need to monitor and analyze web traffic. This paper proposes a novel
solution for estimating the number of HTTP/3 responses in a given QUIC connection by an observer.
This estimation reveals server behavior, client-server interactions, and data transmission efficiency,
which is crucial for various applications such as designing a load balancing solution and detecting
HTTP/3 flood attacks.
The proposed scheme transforms QUIC connection traces into a sequence of images and trains machine learning (ML) models to predict the number of responses. Then, by aggregating images of a
QUIC connection, an observer can estimate the total number of responses. As the problem is formulated as a discrete regression problem, we introduce a dedicated loss function. The proposed scheme
is evaluated on a dataset of over seven million images, generated from 100, 000 traces collected from
over 44, 000 websites over a four-month period, from various vantage points. The scheme achieves
up to 97% cumulative accuracy in both known and unknown web server settings and 92% accuracy
in estimating the total number of responses in unseen QUIC traces.
1 Introduction
Quick UDP Internet Connections (QUIC) Iyengar and Thomson (2021) is gradually replacing TCP as the main internet
transport protocol due to its enhanced security and performance. Stream multiplexing is one of the most important
features of QUIC. It allows an HTTP Bishop (2022) server to send the client several HTTP objects simultaneously,
one on each stream, while avoiding head-of-the-line blocking.
The data in each stream is carried by different QUIC frames. Every QUIC packet can carry multiple frames, each
containing data belonging to a different object. Since the various streams are independent of each other, when a stream
is delayed due to a packet loss, there is no impact on the progress of the other streams Bishop (2022); Kuhlewind and ¬®
Trammell (2022). HTTP/3 is a mapping of HTTP semantics over QUIC. HTTP/3 communication over QUIC streams
is performed using requests and responses, such that each request is allocated a stream from the client to the server,
and each response is allocated a stream from the server to the client Bishop (2022).
This paper considers an observer listening to the channel between the QUIC client and server. This observer sees the
data packets sent in both directions and aims to estimate the number of objects this connection carries. This
information can be useful for various applications. The most important application is HTTP/3 load balancing. A load
balancer can successfully balance the load it assigns to different machines if it is able to estimate the load imposed
by each connection Shahla et al. (2024). This is difficult with HTTP/3, because the load balancer does not know how
many requests are sent by a client to the server on different QUIC streams1
. The scheme presented in this paper can
help to address this problem.
1This is also difficult with HTTP/2, because multiple requests can also be sent by an HTTP/2 client over one TCP connection.
In this case, different streams are implemented by HTTP and not by QUIC. The same approach proposed here for HTTP/3 over
QUIC is applicable for HTTP/2 over TCP.
Preprint
DecQUIC image generation pipeline
(a) Time series statistics
captures
(b) Number of packets to time bins (c) RGB image
Figure 1: Generation of an image representing observed QUIC packets. The captured connection trace is windowed
into overlapping temporal intervals. In each temporal window, the number of packets sent by the client and the server
are binned into time bins. The obtained two-dimensional histograms (number of packets vs. time) are represented as
an RGB image, with the green channel representing the packets sent by the client, the red channel representing the
packets sent by the server, and the blue channel being unused.
Another use case is detecting HTTP/3 flood attack Chatzoglou et al. (2023). In this attack, multiple HTTP/3 requests
were sent to the server over a single connection. As indicated in Chatzoglou et al. (2023), identifying such an attack is
challenging, because the attack pattern is almost identical to that of the normal traffic.
This paper presents a new scheme called DecQUIC, which can be used by an observer to estimate the number of
request/response pairs in a QUIC connection. To train this scheme, we extend the work of Horowicz et al. (2022);
Shapira and Shavitt (2019). A QUIC connection trace is first captured and divided into multiple window times. Then,
for each window, two histograms are generated: the first describes the number of packets sent by the client during this
window, and the second describes the number of packets sent by the server during this window. These histograms are
used, together with information about the length and time of each packet and density, to generate an RGB image. In this
image, the red channel represents the normalized number of packets sent by the server, the green channel represents
the normalized number of packets sent by the client during the corresponding time window, and the blue channel is not
used. The above process is illustrated by Figure 1. As mentioned, visualizing traffic flows as images was introduced
in Shapira and Shavitt (2019), but their images were grayscale with a single channel, and contained no information
about packet density. Therefore, it is insufficient for the task of predicting the number of HTTP/3 responses. The
single-channel approach offers only a broad traffic overview, limiting its ability to distinguish between client-to-server
and server-to-client. This is crucial in QUIC, where HTTP/3 requests and responses involve multiplexed streams.
Moreover, QUIC‚Äôs complexity, (stream multiplexing and independent packet handling), requires separate analysis of
traffic directions.
After the above scheme transforms a QUIC trace into a sequence of RGB images representing the connection, a ML
model is trained to receive a single image and predict the number of HTTP/3 responses that start in each image during
every time window. This scheme works both online and offline. In the former case, it estimates the number of responses
sent by the server rapidly for a predetermined short period of time (for example, the first 100ms of a connection). In
the latter case, it estimates the total load imposed on a server during a long period of time. The considered problem is
not a classic classification task because the misclassification errors depend on the distance between the real number of
responses and the predictions. It is also not a standard regression task, as the numbers of responses are discrete. We,
therefore, formulate a discrete regression task and develop a special loss function for it.
To train and evaluate DecQUIC, we introduce a labeled dataset comprising over 100,000 QUIC traces from more
than 44,000 websites (URLs), collected over a four-month period, from various vantage points. These traces provide
the foundation for generating more than two million images, which were configured based on window length, pixel
resolution, and normalization. We demonstrate that DecQUIC can achieve up to 97% accuracy when utilizing images
with time windows of ùëá = 0.1 or ùëá = 0.3 seconds. The flexibility of the dataset allows for configurable analysis at
different granularities, showcasing the utility of QUIC traces in performance evaluation.
The rest of this paper is organized as follows: Section 2 reviews related work. Section 3 describes the proposed deep
learning (DL) scheme and its challenges. Section 4 discusses the proposed loss function used for training the ML
models. Section 5 presents an evaluation of the trained ML models on out-of-training sample QUIC traces and out-ofdistribution sample web servers. Section 6 uses the trained ML models to estimate the number of HTTP/3 responses
over complete QUIC traces. Finally, Section 7 concludes the paper.
2
Preprint
2 Related Work
The rise of encrypted traffic in recent years has led to a marked increase in the adoption of flow-based techniques that
depend on ML for the analysis of statistical or time series data. Among these techniques are ùëò-Nearest Neighbors
(KNN), Random Forest (RF), Naive Bayes (NB), and Support Vector Machines (SVM) Pacheco et al. (2020); Sun
et al. (2010); Velan et al. (2015). DL and deep neural network (NN) techniques have surfaced more recently for the
classification of encrypted communications Lotfollahi and Siavoshani (2020); Wang et al. (2018).
The authors in Tong and Tran (2018) proposed a two-stage traffic classification approach using RF and convolutional neural networks (CNN), demonstrating high accuracy (up to 99%) across various QUIC-based services. In
another work Rezaei and Liu (2020), the authors developed a multi-task traffic classification technique using CNN
that predicted bandwidth requirements, flow duration, and traffic class, outperforming single-task and transfer learning approaches with up to 90% accuracy on ISCX Ghorbani et al. (2012) and QUIC Chadi Assi (2020) public datasets.
The same authors later proposed a semi-supervised method using CNN that showed potential even when trained on a
small dataset. Their work differs from ours in two major ways. To begin, their method is trained and evaluated only
on Google‚Äôs services using Google web servers, as opposed to ours, which is trained and evaluated on many different
web servers. Second, they classify the type of service rather than the characteristics of the QUIC connection itself.
In Almuhammadi et al. (2023), the authors addressed the difficulties presented by encrypted traffic using five different
ensemble ML techniques: RF, Extra Trees, Gradient Boosting Tree, Extreme Gradient Boosting Tree (EGBT), and
the Light Gradient Boosting Model (LGBM). They assessed these ML models using a publicly accessible dataset
and found that EGBT and LGBM perform particularly well in terms of high accuracy and efficiency when it comes to
classifying encrypted QUIC traffic. Their dataset includes five distinct QUIC traffic types that were created specifically
for ML classification using only the Google web server, whereas ours includes many web servers and over 72, 000
distinct traces.
The authors in Secchi and Cassara (2022) showed work utilizing SVM, KNN, RF, and NN models for encrypted traffic `
classification, demonstrating impressive results, with all models achieving over 97% accuracy on QUIC traffic. Their
work, unlike ours, is intended for QUIC over satellite only, mitigating the different client-server behaviors among
different web servers. In a different work, the authors in Towhid and Shahriar (2022) developed a self-supervised
approach for encrypted network traffic classification that, despite having few labeled data, achieved 98% accuracy on
the QUIC dataset, surpassing the baseline by 3%. Unlike us, the QUIC dataset only contains Google connections and
its classification technique works exclusively on (numerous) Google services. We on the other hand, estimate certain
characteristics of the connection itself.
In their work, the authors of Izadi et al. (2022a) devised a method to differentiate between VPN and non-VPN encrypted traffic using the ISCX VPN-non-VPN dataset. This approach combines the ant-lion meta-heuristic algorithm,
the self-organizing map algorithm, and CNN for feature extraction and classification, yielding a high accuracy of 98%
on the test data. Analogously, a separate study Izadi et al. (2022b) by the same authors employed data fusion methods and DL for traffic classification on the same dataset. Their classification, unlike ours, is whether it is a VPN or
non-VPN data connection.
CESNET-QUIC22 (Luxemburk et al., 2023a) is a QUIC traffic dataset collected from backbone lines of a large Internet
service provider. It contains over 153 million connections and 102 service labels, captured during one month.
In Luxemburk et al. (2023b), the authors demonstrate three techniques for QUIC service classification using the
CESNET-QUIC22 dataset. They do not deal with out-of-distribution settings, in which web servers that were not
present in the training set are visible during evaluation, whereas we do. Additionally, they classify services rather
than connection characteristics. In Geiginger (2021) the CESNET-QUIC22 dataset was used once again to evaluate
the effectiveness of various classification models, including a multi-modal CNN, LightGBM, and IP-based classifiers.
Their study sets a new standard for fine-grained service classification within encrypted QUIC traffic, highlighting the
models‚Äô abilities to discern web services accurately in a secure and encrypted communication framework. The authors
of Geiginger (2021) do not deal with out-of-distribution settings, in which web servers that were not present in the
training set are visible during evaluation; we, however, do.
3 DecQUIC Framework
We consider an observer who can see the QUIC encrypted packets transmitted from the client to the server, and
vice versa. For each packet, the observer knows its direction, length, and the observed time. DecQUIC uses this
information to convert QUIC traces into representative colored images, which are then suitable for ML models to train
on. To convert the captured QUIC traces into time-series data, the sliding window technique Frank et al. (2001) is
3
Preprint
used. This technique requires two parameters: the window length and the overlap between consecutive windows. We
show results for two different sliding window lengths, ùëá = 0.1 and ùëá = 0.3 seconds. During training, we use a 90%
overlap between windows to increase the number of images. For evaluation, we use a 0% overlap to ensure the images
represent the entire connection, allowing us to estimate the total responses in the connection, without double-counting
responses.
Figure 1 shows an example of the construction steps for an image with a window length of 0.3 seconds from a trace.
During step (a), some of the trace statistics are collected: the time when the observer sees this packet, the packet‚Äôs
length, and the packet‚Äôs direction. Afterwards, each window is split into 32 time bins. For example, for a 0.3-second
window, each bin contains 9.375 milliseconds of traffic. Step (b) shows histograms with ùëÄ = 32 time bins for the
considered window. The upper one is for the packets sent by the server, and the lower one is for packets sent by the
client. The horizontal axis represents the time bins, and the vertical axis represents the number of packets received
during each bin. For example, in the 8-th time bin (boxed in orange), the server sent 10 packets and the client sent 19
packets. Step (c) shows the image constructed for the considered example. The image represents the packet length
statistics and the number of packets. Once the traces are captured, the image dataset generation process begins. For
each trace, the SSL keys are stored in a separate file (and are included in the dataset), and then used to decrypt the
relevant QUIC packets and determine the number of responses within each window (thereby labeling the images). The
label for an image indicates the number of HTTP/3 responses the observer captured during the corresponding window.
Figure 2 shows an example of the constructed image. The image is constructed on an ùëÄ √ó ùëÅ equispaced grid. The
horizontal dimension represents different time window locations, while the vertical dimension represents different
packet lengths. Thus, each packet is binned into one of the ùëÄ √ó ùëÅ bins according to its length and time. In all our
experiments, we choose ùëÄ = ùëÅ = 32 as a compromise between the image size and the image resolution. When fine
bins are used, the increased image size increases the training and inference burden, but with little gain in accuracy.
Coarser bins were observed to impair the model‚Äôs performance. Our tested values are 32, 64, 128 and 256, as further
discussed in Horowicz et al. (2022).
1 5 10 15 20 25 30 Time
32 equal-sized
packet length
bins
32 equal-sized time bins Window length: T=0.3/0.1 seconds
1
5
10
15
20
25
30
Normalized
Packet length
pixel (7,12)
brightest
green
pixel (23,10)
brightest red
pixel (9,26)
shared pixel
Red channel: Server-to-Client
Green channel: Client-to-Server
Figure 2: A DecQUIC image, representing QUIC connection activity. Pixel positions represent histogram bins (horizontal and vertical axes corresponding to time and packet
length, respectively). The values of the red and green channels represent normalized, per-window, histogram counts
of the response and request packets, respectively.
In the resulting image, the pixel at location (ùëñ, ùëó) represents the normalized number of packets whose length
falls within the ùëó-th bin received during the temporal
span of the ùëñ-th time bin. The pixel‚Äôs RGB values represent the normalized number of packets (i.e., density)
sent from the server to the client (red) and from the client
to the server (green). The blue channel is unused. The
time interval spanned by the ùëñ-th bin is [ùëñŒîùë°, (ùëñ + 1)Œîùë°),
where Œîùë° = ùëá/ùëÄ and ùëá denotes the window length. In
our experiments, we used ùëá = 0.1 and ùëá = 0.3 seconds.
To be counted in length bin ùëó, the length of a packet
should be in the range of [ùëóŒîùëô, ( ùëó +1)Œîùëô] with Œîùëô = ùêø/ùëÅ
and ùêø = 1, 500 bytes denoting the maximum transmission unit (MTU). Histogram counts are normalized per
channel window-wise using min-max normalization Patro and Sahu (2015), ùë•nrm = (ùë• ‚àí ùë•min)/(ùë•max ‚àí ùë•min),
where ùë• and ùë•nrm are the original and normalized packet
counts, respectively, and ùë•min and ùë•max are the minimum
and maximum values of the packet count for the specific
direction in the considered window, respectively. The
normalized value is multiplied by 255 to fit an 8-bit image format. If there is no traffic for a specific window, all
pixels will contain the value zero. Note that the shortest
QUIC packet is longer than what is represented by the
first length bin. Therefore, the first row of the image grid
consistently exhibits pixels with a value of zero.
Figure 2 shows different densities for each channel. For
example, during time bin ùëñ = 7, different shades of green
are displayed. This indicates that the client sent packets
of five different lengths, which fall into bins ùëó = 2, 6, 12, 27, and 28. The five pixels are purely green, indicating
that all the packets observed during bin ùëñ = 7 were sent by the client. The brightness of a pixel increases as its value
approaches 255. Pixel (7, 12) is the brightest across the whole window in the green channel and it represents 8 packets.
This means that the largest number of packets sent by the client during the window is observed during time bin ùëñ = 7,
4
Preprint
ReLu
Input = 3
Output = 64
Kernel = 6
Stride = 1
CNN-2D
Input = 256
Output = 512
Input = 512
Attention
Query
input = 128
output = 128
Value
input = 128
output = 128
Calculations
Key
input = 128
output = 128
x
Output of the
last time step (1) ReLu
(2) 0.3 Dropout
GRU
ReLu
Input = 64
Output = 128
Kernel = 3
Stride = 1
ReLu
Input = 128
Output = 256
Kernel = 3
Stride = 1
CNN-2D CNN-2D
Input = 29*256
Output = 256
FC-1
Classes
Probabilities
FC-2
x
x
x
Figure 3: The proposed DecQUIC neural network architecture.
when their length fell in bin ùëó = 12. The other green pixels represent between 2 to 5 packets that are sent by the client.
At time bin ùëñ = 23, the server sent packets of four different lengths, which are classified, based on their length, into
bins ùëó = 7, 10, 15, and 17. The four pixels are purely red, indicating that during time bin ùëñ = 23, only packets sent
by the server are observed. Pixel (23, 10), representing 18 packets, is the brightest within the red channel across the
entire window. The rest of the red pixels represent between 3 and 15 packets sent by the server. Pixel (9, 26) is a
combination of green and red, indicating that during time bin ùëñ = 9, packets from both the client and the server are
observed and their length puts them into bin ùëó = 26.
DecQUIC‚Äôs image construction is an extension of the technique proposed by FlowPic Shapira and Shavitt (2019),
which transforms network flows into images. FlowPic generates images based on packet lengths and their observed
times, with the objective of constructing a grayscale image using a flow-based two-dimensional histogram. However,
FlowPic‚Äôs single-channel approach, while providing a general traffic overview, is insufficient for more nuanced analysis, particularly in the context of QUIC. In QUIC, distinguishing between client-to-server and server-to-client traffic
is critical due to the multiplexed nature of HTTP/3 requests and responses. Furthermore, QUIC‚Äôs inherent complexity‚Äîstemming from stream multiplexing and independent packet handling‚Äînecessitates a more detailed examination
of traffic directions. For those reasons, DecQUIC introduces a separate channel for each direction between a client
and a server, a density factor for the packets‚Äô count in a given window, a configurable number of bins, and uses a very
short time window per each image. The result is an RGB image.
The final step in transforming the task into an ML problem is the creation of a labeled image dataset, from over
100, 000 traces collected from over 44, 000 websites (URLs). Each image in this dataset represents a snapshot of
network activity, labeled with the number of HTTP/3 responses that started to be seen by an observer for every time
window. To this end, the HTTP/3 frames are analyzed using the SSL identified keys and HTTP/3 HEADERS frames.
Figure 3 shows the neural network (NN) architecture used in our experiments. The architecture is based on Ismail Fawaz et al. (2020); Khan et al. (2021). It includes CNN layers, a gated recurrent unit (GRU), and a self-attention
mechanism. Each component plays a crucial role in the estimation task. The initial CNN layers extract spatial features
from the input data. The first convolution layer uses 64 filters with a 6 √ó 6 kernel to capture low-level features such
as rectangles representing packets arriving during consecutive bins. A 6 √ó 6 kernel in a 32 √ó 32 image enables the
ML model to examine large sub-windows of the image, accounting for nearly 20% of the image size. A smaller 3 √ó 3
kernel in the first layer produced inferior results.
To process the low-level features and extract higher-level spatial information, the subsequent layers apply 128 and
256 filters with 3 √ó 3 kernel sizes, respectively. A ReLU activation is used after each convolutional layer to allow
the model to learn more complex features Krizhevsky et al. (2012). The GRU layer processes the output of the
convolutional layer, allowing it to detect temporal patterns in the images. Prior to feeding data into the GRU, we
perform a reshaping operation to ensure the GRU layer correctly interprets the time dimension. This transformation
preserves the temporal order of the data. Unlike traditional NNs, GRUs can learn long-term dependencies in sequential
5
Preprint
(a) 2 responses (b) 6 responses (c) 12 responses
Figure 4: Three examples of DecQUIC image representation of QUIC flows with the number of HTTP/3 responses
annotated next to each image. Note that visually similar images may have highly distinct labels.
data, which makes them ideal for time series tasks Dey and Salem (2017). Following the CNN and GRU layers, a
self-attention mechanism is used. It is a crucial component of the architecture Vaswani et al. (2017), which enables
ML models to focus on the most relevant input sequences. The self-attention module computes attention scores using
the GRU output. It allows the ML models to weigh different parts of the sequence differently, thereby improving their
ability to capture important temporal features. Finally, our architecture consists of two fully connected layers (FC-1
and FC-2) with ReLU activation, interspaced by a 0.3 dropout layer for regularization. The dropout layer helps to
prevent overfitting and ensures that the model generalizes well to new data.
Once the task is formulated as an ML problem, the objective is to predict the number of HTTP/3 responses represented
by each image. This task presents the following three challenges: (1) visually similar images are often assigned highly
divergent labels; (2) the datasets (the ùëá = 0.1 and ùëá = 0.3 window datasets) are imbalanced, complicating the training
process; and (3) the learning task deviates from conventional regression or classification models, which complicates
both the training and evaluation processes. Through the rest of the paper, the term ‚Äúclass‚Äù is used to denote the number
of responses associated with each image (the label).
Figure 4 illustrates the first challenge, visually distinguishing between images. It presents three images, each tagged
with different labels. Figures 4(a), 4(b) and 4(c) show that although the images look similar, their class labels vary
significantly. The server-to-client and client-to-server interaction patterns for images with these labels are strikingly
similar. The packet density on the left side of the images is roughly the same, and the packet lengths fall into almost
identical bins in both directions.
The second challenge is the distribution of classes per image within each dataset. Both datasets are significantly
skewed. Figure 5(a) and Figure 5(b) display the distribution of classes for two window lengths. Notice the very rare
cases of images with more than 15 HTTP/3 responses. As the figures demonstrate, images whose class values are
10 or more are also infrequent in both datasets. To mitigate class imbalance, we developed a dedicated loss function
and implemented a data augmentation technique. Data augmentation enhances the representation of minority classes
by increasing the diversity and quantity of samples, which helps to prevent the ML model from favoring the majority
class.
The images are generated from QUIC traces that are formatted into a 32 √ó 32 pixel grid. Each pixel corresponds to
a unique feature of network traffic over a specific period. Any disruption in the temporal dependencies present in
each image, such as non-order-preserving modifications, may result in the loss of critical information, reducing the
ML model‚Äôs ability to estimate correctly. Thus, data augmentation is only applied to the minority classes (classes
whose values are between 10 and 20), incorporating a minimal noise level Maharana et al. (2022). We used noise
with the standard deviation of ùúé = 2.55 corresponding to 1% of the pixel value, ensuring that the added noise does
not drastically alter the image appearance or disrupt the temporal dependencies. The noise serves, however, to imitate
minor variations, increasing the model‚Äôs robustness and generalization capabilities.
The third challenge is that the learning task cannot be categorized as a standard classification task or a standard
regression task. Rather, it is a discrete regression problem. Consider, for example, an image with 17 responses.
Estimating this number at 16 is better than estimating it at 15 or 19 because, unlike typical classification problems, the
distance from the label is important. To address this issue, we developed a dedicated loss function that considers both
6
Preprint
26.6%
29.0%
16.1%
8.5%
5.8%
3.9%
2.2%
1.6%
1.4%
0.9%
0.9%
0.6%
0.4%
0.3%
0.3%
1.5% Training Data Set
26.3%
29.7%
16.1%
8.6%
5.8%
3.8%
2.2%
1.5%
1.4%
0.9%
0.9%
0.6%
0.4%
0.3%
0.2%
1.5% Test Data Set
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15-20
(a) ùëá = 0.1 window dataset
20.7% 10.0%
16.4%
10.3%
7.8%
5.9%
4.5%
4.7%
4.7%
2.9%
2.5%
2.1%
1.5%
1.1%
1.1%
3.7% Training Data Set
21.7% 9.6%
16.6%
10.3%
7.6%
5.7%
4.5%
4.6%
4.7%
2.9%
2.5%
2.1%
1.4%
1.1%
1.1%
3.6% Test Data Set
(b) ùëá = 0.3 window dataset
Figure 5: Dataset distributions for window lengths ùëá = 0.1 and ùëá = 0.3 seconds.
the imbalanced dataset and the desire to reward the model for correctly predicting classes that are closer to the actual
label than those that are farther away. Section 4 explains the discrete regression loss function in more detail.
4 A Discrete Regression Loss Function
During the development of our model to accurately estimate the number of responses, we experimented with various
conventional loss functions, each designed to address a specific aspect of the task. We first used the Cross-Entropy
Loss, a standard method for classification problems, but it struggled with our dataset‚Äôs inherent class imbalance. We
next considered the Mean Squared Error (MSE) Loss, and Mean Absolute Error (MAE) which are commonly used in
regression tasks, but those did not properly consider the ordinal nature of our labels, and both operate for continuous
labels when the labels in our case are discrete. Additionally, we tested the Huber Loss, which is robust to outliers and
7
Preprint
combines the benefits of classification and regression loss functions, but it did not consider the need to preserve the
ordinal sequence among the classes.
These limitations motivated the development of a new loss function that integrates the advantages of multiple approaches to better suit our needs. To address the challenges outlined in Section 3, the proposed loss function,
ùêø = ùõº FL + (1 ‚àí ùõº) ((ùõΩ ORL + (1 ‚àí ùõΩ)DBL) .
It comprises an aggregate of three terms: (1) a focused loss (FL) term, intended to alleviate class imbalance by
minimizing the relative loss for well-classified cases while emphasizing difficult-to-classify ones; (2) a distancebased loss (DBL) term penalizing the model according to the predicted class‚Äôs distance from the true label; and (3)
an ordinal regression loss (ORL) term that introduces higher penalties for misclassifications that disrupt the natural
ordinal sequence of the dataset, where lower class values occur more frequently.
The FL term Lin et al. (2017) builds on the weighted cross-entropy loss De Boer et al. (2005) by adding a focusing
parameter, ùõæ, which adjusts the influence of each sample on the training process based on the classification confidence.
This parameter, ùõæ, modifies the loss function by scaling the loss associated with each sample by (1 ‚àí ùëùùë°)
ùõæ
, where ùëùùë°
is the predicted probability of the true class y. This scaling reduces the loss from easy examples (where ùëùùë°
is high),
thereby increasing it for hard, misclassified examples, focusing training efforts on samples where improvement is most
needed. Accordingly, the term is:
FL(x, y) = E(x,y)

‚àíùë§(ùë¶) ¬∑
1 ‚àí yÀÜ ùë¶ (x)
 ùõæ
¬∑ y
T
log yÀÜ(x)

,
where x denotes the input sample, y is the one-hot encoded ground truth label, yÀÜ(x) represents the model‚Äôs output
of class probabilities, yÀÜ ùë¶ (x) denotes the predicted probability of the true class ùë¶, and ùë§(ùë¶) is a weight inversely
proportional to the class frequency of ùë¶ in the training dataset. By assigning a higher weight to less frequent classes,
the model places more emphasis on accurately classifying these classes during training. It is an effective strategy for
dealing with class imbalance Aurelio et al. (2019); Tian et al. (2020); Lin et al. (2017). FL thus minimizes the relative
loss for well-classified examples, while emphasizing difficult-to-classify ones.
The DBL term Wang et al. (2020)
DBL = E(x,ùë¶)
"‚àëÔ∏Å
ùëñ
ùë¶ÀÜùëñ(x) ¬∑ |ùëñ ‚àí ùë¶|
#
,
with ùë¶ denoting the ground truth class, is essentially a discrete regression loss that penalizes the model‚Äôs output
according to the predicted class‚Äôs distance from the true label. The distance is computed as the absolute difference
between the class indices and the target class.
Finally, the ORL term Rennie and Srebro (2005); Frank and Hall (2001) is given by
ORL = E(x,y)

‚àíy
T
log ùúé(yÀÜ) ‚àí (1 ‚àí y)
T
log ùúé(1 ‚àí yÀÜ)

,
with ùúé denoting the sigmoid function saturating the input between 0 and 1. ORL uses a binary cross-entropy loss
function, which compares the activation of each output neuron to a target that shows if the true class is greater than or
equal to each class index, thus helping the model determine the order of the classes. Both DBL and ORL consider the
relations between classes; they do so in different ways: DBL penalizes predictions based on the numerical distance,
while ORL makes explicit use of the classes‚Äô order. It focuses on preserving the correct order among predictions rather
than the numerical distance between them.
The parameters ùõº, ùõΩ, and ùõæ in the aggregated loss are used to balance the contributions of these three components to
the combined loss. ùõº is a parameter that controls the balance between the FL term and the ORL and DBL combination.
A higher value of ùõº gives more weight to the FL term, while a lower value gives more weight to the ORL and DBL
combination. ùõΩ is a parameter that controls the balance between the ORL and DBL terms. A higher value of ùõΩ gives
more weight to the ORL term, while a lower value gives more weight to the DBL term. ùõæ is a parameter used inside the
FL component to adjust the focusing effect of the FL term. A higher ùõæ increases the effect of the focusing mechanism.
This means the model pays more attention to correcting its worst mistakes, which is useful in highly imbalanced
scenarios. Lower ùõæ values reduce the impact, making the loss more like a standard cross-entropy loss where each
misclassification is weighted more uniformly.
In Section 5, we present an ablation study on the terms of the proposed loss function, demonstrating the importance of
each term for achieving the best performance.
5 Evaluating the Machine Learning Models
We now present a quantitative evaluation of the proposed framework in two settings: when the web servers are known
to the observer, and when they are not. In the former case, a set of models were trained and evaluated exclusively on

Preprint
Table 1: Summary statistics of QUIC traces and the number of images per dataset for each web server. Each web
server containing multiple websites (URLs).
Web Server Websites Traces ùëá = 0.1 ùëá = 0.3
youtube.com 399 2,109 139,889 54,659
semrush.com 1,785 9,489 474,716 221,477
discord.com 527 7,271 623,823 235,248
instagram.com 3 207 17,003 7,112
mercedes-benz.com 46 66 9,987 2,740
bleacherreport.com 1,798 8,497 781,915 331,530
nicelocal.com 1,744 1,666 148,254 48,900
facebook.com 13 672 25,919 10,988
pcmag.com 5,592 13,921 1,183,717 385,797
logitech.com 177 728 56,792 28,580
google.com 1,341 2,149 81,293 29,068
cdnetworks.com 902 2,275 207,604 85,707
independent.co.uk 3,340 3,453 176,768 68,480
cloudflare.com 26,738 44,700 1,347,766 341,488
jetbrains.com 35 1,096 34,934 18,470
pinterest.com 43 238 6,465 2,360
wiggle.com 4 0 0 0
cnn.com 27 2,127 91,321 59,671
the QUIC traces pertaining to the web servers assumed at inference time. In the latter case, a leave-two-servers-out
evaluation was performed. We opted to conduct a leave-two-servers-out evaluation instead of a leave-one-server-out
evaluation due to the presence of 18 web servers. Our intention is to reserve approximately 10% of the data for outof-distribution evaluation. More details about the training and test set constructions are provided later in this section.
In both settings, different models were trained with windows of ùëá = 0.1 and ùëá = 0.3 seconds. They were all trained
on 18 different web servers, with 44, 000 websites and 100, 000 traces that were captured over a four-month period.
Table 1 provides summary statistics per web server; more detailed statistics broken down per web server for each class
are provided in the Appendix. Classes with labels non-superior to 20 constitute 90% of the traces in the ùëá = 0.3-
second window dataset and 95% of the traces in the ùëá = 0.1-second window dataset. Due to their scarceness (e.g.,
only 0.003% of the images are labeled as class 21.), classes above 20 were excluded from the training and test sets.
5.1 Results for Known Web Servers
First, we consider the case when the web servers are known to the observer monitoring the connection. Each web
server‚Äôs traces were randomly split into training and test sets using the 80 : 20 ratio, ensuring out-of-training-sample
evaluation. We performed five random splits, each time training a new ML model. The training was performed with a
batch size of 64 images using the Adam optimizer Kingma and Ba (2014) with the ReduceLROnPlateau learning rate
scheduler. When a plateau in validation loss is detected, the scheduler applies a 30% reduction in the learning rate,
allowing for more fine-tuned modifications as the training advances. To reduce the risk of overfitting, an early stopping
technique was used, with a patience parameter of six epochs (i.e., the training was stopped whenever the validation
loss did not improve for six consecutive epochs). A grid search was performed to find the optimal values of ùõº, ùõΩ, and
ùõæ (of the loss function). The values considered were ùõº ‚àà {0, 0.3, 0.5, 0.7, 1}, ùõΩ ‚àà {0, 0.4, 0.6, 1}, and ùõæ ‚àà {1, 2, 3}.
This grid search also allowed us to systematically evaluate the impact of each parameter on the model‚Äôs performance.
The optimal combination was chosen based on the lowest validation loss seen during the training process. The optimal
values for ùëá = 0.3 seconds were found to be ùõº = 0.7, ùõΩ = 0.4, and ùõæ = 2, while for ùëá = 0.1 seconds, ùõæ = 3 produced
the best results with the same values of ùõº and ùõΩ.
The box plot in Figure 6 illustrates the accuracy of predicting the correct classes on out-of-training sample traces with
windows of lengths ùëá = 0.1 and ùëá = 0.3 seconds, for one of the five iterations. The horizontal axis represents true
labels, while the vertical axis represents predicted labels belonging to one of the 21 discrete classes. The vertical boxes
show the 25-th, 50-th, and 75-th percentiles for each class prediction. In Figure 6(a) for the lower value classes (classes
0, 1 and 2), the rectangles appear as single lines, indicating minimal variation in the predicted values. This shows that
the model‚Äôs predictions for these classes are consistently close to their true values. As the true labels increase in value,
however, the rectangles widen, reflecting an increased prediction error variance.
Figure 6(b) demonstrates the same trends with the ùëá = 0.3-second window. Nevertheless, this model differs in two
key points. Firstly, its accuracy for lower class values is higher and extends to class values of 4 rather than up to 2.
9
Preprint
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
True Labels
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Predicted Labels
(a) Window length ùëá = 0.1 second
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
True Labels
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Predicted Labels
(b) Window length ùëá = 0.3 second
Figure 6: Prediction errors assuming known web servers. Red lines indicate the median predicted value; blue boxes
show the 25 ‚àí 75% confidence intervals (iteration 1).
Table 2: CAP results for known web server setting, for five randomly selected splits of training and test sets using
ùëá = 0.1 and ùëá = 0.3 window length datasets.
Iteration ùëá = 0.1 ùëá = 0.3
¬±1 ¬±2 ¬±1 ¬±2
1 0.93 0.97 0.91 0.96
2 0.92 0.96 0.90 0.97
3 0.93 0.98 0.91 0.95
4 0.94 0.97 0.92 0.93
5 0.91 0.96 0.92 0.94
Secondly, the model demonstrates improved accuracy at the upper-class values (16 ‚àí 20). The prediction distributions
are tighter and tend to be less biased. The enhanced performance observed with a ùëá = 0.3-second window is attributed
to the dataset‚Äôs distribution (Figure 5). In the ùëá = 0.1-second window dataset, labels 0, 1 and 2 make up roughly
75% of the data, with the higher classes being represented in smaller proportions. Conversely, in the ùëá = 0.3-second
window dataset, there is a more even distribution, with labels 0, 1 and 2 comprising only about 47% of the total dataset.
For an online use case, a ùëá = 0.3-second window is a better choice for an observer to use, as every image is considered
standalone.
Additionally, we introduce a Cumulative Accuracy Profile (CAP) metric, which provides a refined measure of classification accuracy by incorporating a tolerance level for each prediction. Unlike traditional metrics such as confusion
matrices that require exact matches between predicted and true labels, CAP allows for a specified degree of tolerance,
accommodating predictions that are close to the correct class. Formally, it is defined as:
CAP¬±ùëò (y, yÀÜ) =
1
ùëõ
‚àëÔ∏Åùëõ
ùëñ=1
1(|ùë¶ùëñ ‚àí ùë¶ÀÜùëñ
| ‚â§ ùëò),
where y represents the vector of true class labels, yÀÜ denotes the model‚Äôs predictions, ùëò specifies the tolerance level
(e.g., ¬±1 or ¬±2 classes), ùëõ is the total number of samples, and 1(¬∑) is the indicator function that evaluates to 1 if the
condition is met and 0 otherwise. This metric thus quantifies the proportion of samples where the model‚Äôs predictions
fall within the allowed tolerance around the true class. For example, a CAP score of 91% within a tolerance of ¬±1
means that 91% of the predictions are at most one class away from the correct label.
For the models trained using both datasets, ùëá = 0.1 and 0.3 second window dataset, the CAP results are presented in
Table 2. We did not perform stratified sampling for the classes.
10
Preprint
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
True Labels
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Predicted Labels
Figure 7: Prediction errors assuming unknown web servers. The testing servers are ‚Äúindependent.co.uk‚Äù and
‚Äúgoogle.com‚Äù, using a window length of ùëá = 0.3 seconds. Red lines indicate the median predicted value; blue
boxes show the 25-75% confidence intervals.
Table 3: CAP results for unknown web server setting, for ten randomly selected iterations of two web servers used for
testing and the remaining for training, using the ùëá = 0.3 window length dataset.
Testing Servers ¬±1 ¬±2
bleacherreport.com, cloudflare.com 0.62 0.76
facebook.com, cdnetworks.com 0.59 0.72
logitech.com, mercedes-benz.com 0.66 0.77
bleacherreport.com, semrush.com 0.63 0.75
independent.co.uk, google.com 0.83 0.90
cnn.com, facebook.com 0.82 0.88
discord.com, youtube.com 0.66 0.84
discord.com, google.com 0.61 0.80
discord.com, independent.co.uk 0.83 0.88
bleacherreport.com, google.com 0.78 0.85
5.2 Results for Unknown Web Servers
In the following, we present evaluation results for the unknown web server setting, in which the observer has no prior
knowledge of which web servers to monitor. The task is to investigate if it is possible to learn on one set of web servers
and do the evaluation on another. As client‚Äìserver dynamics can vary across different web servers, this task essentially
evaluates the model‚Äôs out-of-distribution performance. To achieve this, both datasets are divided into ten randomly
selected combinations of web servers, with two reserved for testing and the remaining for training. The combination of
training and testing web servers has a significant impact on the learning process‚Äôs results due to the class distribution
across the datasets. For example, if the ‚Äúsemrush.com‚Äù web server is in the testing set but not in the training set, the
majority of the higher value classes will be left out of training for this combination of web servers. This makes it
difficult for an ML model to generalize effectively for unseen images for the higher-value classes. Furthermore, if we
select web servers that do not have any higher-value class images (such as ‚Äúinstagram.com‚Äù or ‚Äúpcmag.com‚Äù), the ML
model will not be able to estimate higher-value classes. The paper does not include image statistics per web server
due to space constraints. All models were trained using the same method as in the previously described experiments;
in each iteration, a different model was trained and evaluated.
The box plot in Figure 7 depicts one of the ten iterations for the ùëá = 0.3-second window dataset. For this iteration,
‚Äúindependent.co.uk‚Äù and ‚Äúgoogle.com‚Äù were picked at random as the testing web servers, and the remaining web
servers were used for training. Figure 7 shows that for the lower value classes (0 ‚àí 1), the model‚Äôs predictions are
11
Preprint
Table 4: CAP results for unknown web servers setting, for ten randomly selected iterations of two web servers used
for testing and the remaining for training, using the ùëá = 0.1-second window length dataset.
Testing Servers ¬±1 ¬±2
jetbrains.com, semrush.com 0.69 0.78
pcmag.com, discord.com 0.86 0.94
instagram.com, cloudflare.com 0.79 0.90
instagram.com, bleacherreport.com 0.78 0.87
youtube.com, jetbrains.com 0.86 0.92
pcmag.com, cloudflare.com 0.80 0.89
facebook.com, nicelocal.com 0.75 0.85
cdnetworks.com, independent.co.uk 0.71 0.81
cnn.com, facebook.com 0.86 0.90
youtube.com, nicelocal.com 0.81 0.87
very accurate. For mid-range class values (2 ‚àí 12), the model‚Äôs predictions are within an acceptable tolerance level of
¬±2, while for the higher-value classes, the performance, clearly, has deteriorated. This is illustrated by a clear trend
wherein predictions spread more widely in higher-value classes. The CAP results‚Äô accuracy is 83% at ¬±1 tolerance
and 90% at ¬±2 tolerance. Table 3 provides additional CAP results for each iteration.
Using a similar method, we evaluated the ùëá = 0.1-second window dataset, randomly choosing a pair of web servers
for testing while the remaining web servers were used for training. The obtained results were similar to those using the
ùëá = 0.3-window dataset, where the different ML models predicted the lower values with very high accuracy, but for
the mid- and high-range class values, the predictions were more spread out. Table 4 provides additional CAP results
for each iteration.
6 Evaluating on Complete Traces
This section presents results for estimating the total number of HTTP/3 responses in a trace. For this evaluation, new
images were generated with no overlap between the windows, using the same test traces that were used before
(Section 5, iteration 1, known web server scenario). The images were fed sequentially through the trained models,
whose predictions were summed and compared to the sums of the trace‚Äôs true label.
Figure 8 shows prediction results on the same traces used in Section 5, using the ùëá = 0.1- and ùëá = 0.3-second
subdivisions. The same traces were used to create the images. Both figures present a scatter plot in which the parameter
ùúÉ, ranging between 0 and 1, modulates the transparency of the plot. At ùúÉ = 0, a point placed in the plot is fully
transparent, whereas at ùúÉ = 1, it is opaque. In these plots ùúÉ is set to 0.05 to ensure high transparency and optimize
the visual distinction between areas of high and low point density in cases of significant overlap among the roughly
12, 000 data points in each plot. In this plot, each point represents the summed labels or predictions over the images of
a trace. For example, if a trace is composed of five non-overlapping images whose true labels are 1, 0, 2, 4 and 1, then
the true label of that trace is 8; if the model‚Äôs predictions are 1, 0, 3, 4 and 1, for the same images, then the summed
prediction is 9, and that trace is represented in the plot as the (8, 9) point, with ùúÉ = 0.05 density. If another trace has
the same aggregated values and is placed at the same (8, 9) point, then it is placed on top of the previous point, thus
making that point darker.
Figure 8(a) illustrates the scatter plot for predictions from the ML model trained using ùëá = 0.1-second window images,
while Figure 8(b) displays results for ùëá = 0.3-second window. The test dataset includes 12, 520 traces with an average
of 21.2 images per trace for ùëá = 0.1-second window images and 12, 142 traces with an average image of 7.5 per trace
for ùëá = 0.3 seconds. The figures highlight significant improvements in the performance of the two ML models: first,
the ùëá = 0.3-second ML model (that was trained using the ùëá = 0.3 window dataset) has 71% of predictions within ¬±3
of a perfect prediction, whereas the ùëá = 0.1-second model achieves 92.6%, demonstrating a nearly 20% improvement
in accuracy across entire traces. We use a ¬±3 tolerance level because for both window lengths, the points represent
the aggregated prediction sum and, thus, the aggregated errors as well. Therefore, a higher tolerance level is required
since the average number of images per trace is 7.5 and 21.2 for the ùëá = 0.3-second and ùëá = 0.1-second, respectively.
Secondly, the predictions of the model that was trained using a ùëá = 0.1-second window are notably more aligned
along the diagonal, showing less deviation compared to those of the model that was trained using a ùëá = 0.3-second
window, suggesting that finer timing resolutions enhance the performance for the cumulative prediction.
Figures 8(a) and 8(b) illustrate a notable difference in predictive behavior between models that were trained and
evaluated with ùëá = 0.3‚àí and ùëá = 0.1‚àísecond window sizes. Specifically, they show the presence of diagonal patterns
12
Preprint
0 5 10 15 20 25 30 35 40
True Labels
0
5
10
15
20
25
30
35
40
Predictions
Perfect Prediction
Within ¬±3: 92.6%
(a) Window length ùëá = 0.1 second
0 10 20 30 40 50 60 70 80 90
True Labels
0
10
20
30
40
50
60
70
80
90
Predictions
Perfect Prediction
Within ¬±3: 71.0%
(b) Window length ùëá = 0.3 second
Figure 8: Scatter plots demonstrating the predictive results, where each point represents the summed predictions of a
trace compared to its true label, with transparency set to 0.05 to distinguish point density in overlapping areas.
in the predictions of the ùëá = 0.3 model on the test set that are absent in the ùëá = 0.1 predictions. This phenomenon
exists for several reasons: (1) When using a ùëá = 0.1 subdivision, a very high percentage of the images‚Äô true labels
have lower class values, and the model that was trained using the ùëá = 0.1 window dataset is very accurate for low
value classes, whereas a ùëá = 0.3 subdivision yields images with higher class values, hence increasing the variance of
the true labels, when both models perform worse for the higher value classes as opposed to the lower class value; and
(2) any incorrect prediction by either model contributes to an increase in the cumulative predictions for the remainder
of the considered trace, thereby elevating the overall predicted values.
Both figures show that choosing the optimal window length is difficult and use-case-dependent. While shorter windows
improve overall accuracy in cases where an aggregation of images is more important (as seen in this section) and offline
analysis is available, longer windows improve the accuracy when examined on a single image (as seen in Section 5).
Using shorter windows, however, exacts a higher training and inference cost. Section 5 demonstrates that DecQUIC
has the capability to estimate out-of-server-distribution for entire connections.
7 Conclusion
We studied the problem of estimating the number of HTTP/3 responses in a given QUIC connection, acknowledging its impact on network management, load balancing, service quality optimization, and user security. Despite the
complexities introduced by the encryption inherent in QUIC connections, as well as the unstable conditions of the
internet and user behavior, we successfully estimate the number of responses using DL. We created a dataset of over
seven million images from over 100, 000 HTTP/3 communication QUIC traces and evaluated the proposed models
in two settings: when the web server is known to the observer and when it is unknown. The experiments conducted
in both settings achieved remarkably high levels of accuracy, reaching up to 97% CAP accuracy. Furthermore, we
demonstrated that the total number of HTTP/3 responses associated with each QUIC connection from over 12, 000
traces can be estimated with a very high accuracy of 92.6%.
References
Sultan Almuhammadi, Abdullatif Alnajim, and Mohammed Ayub. 2023. QUIC Network Traffic Classification Using
Ensemble Machine Learning Techniques. Applied Sciences 13, 8 (2023), 4725.
Yuri Sousa Aurelio, Gustavo Matheus De Almeida, Cristiano Leite de Castro, and Antonio Padua Braga. 2019. Learning from imbalanced data sets with weighted cross-entropy function. Neural processing letters 50 (2019), 1937‚Äì
1949.
13
Preprint
Mike Bishop. 2022. HTTP/3. RFC 9114. https://doi.org/10.17487/RFC9114
Mohamed Abdelaziz Chadi Assi, Mohamed Farhan Husain. 2020. QUIC Dataset: A Comprehensive Dataset for QUIC
Traffic. https://www.unb.ca/cic/datasets/quic.html. Last accessed: July 21, 2024.
Efstratios Chatzoglou, Vasileios Kouliaridis, Georgios Kambourakis, Georgios Karopoulos, and Stefanos Gritzalis.
2023. A hands-on gaze on HTTP/3 security through the lens of HTTP/2 and a public dataset. Computers & Security
125 (2023), 103051.
Pieter-Tjerk De Boer, Dirk P Kroese, Shie Mannor, and Reuven Y Rubinstein. 2005. A tutorial on the cross-entropy
method. Annals of operations research 134 (2005), 19‚Äì67.
Rahul Dey and Fathi M Salem. 2017. Gate-variants of gated recurrent unit (GRU) neural networks. In 2017 MWSCAS.
IEEE, IEEE, 1597‚Äì1600.
Eibe Frank and Mark Hall. 2001. A simple approach to ordinal classification. In ECML 2001: 12th European Conference on Machine Learning. Springer, Springer, 145‚Äì156.
Ray J Frank, Neil Davey, and Stephen P Hunt. 2001. Time series prediction and neural networks. JIRS 31 (2001),
91‚Äì103.
Lisa-Marie Geiginger. 2021. Classification of Encrypted QUIC Network Traffic. Ph. D. Dissertation. Wien.
Ali A. Ghorbani, Wei Lu, and Mahbod Tavallaee. 2012. ISCX Intrusion Detection Evaluation Dataset. https:
//www.unb.ca/cic/datasets/ids.html. Last accessed: July 21, 2024.
Eyal Horowicz, Tal Shapira, and Yuval Shavitt. 2022. A few shots traffic classification with mini-flowpic augmentations. In 22nd IMC. 647‚Äì654.
Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte Pelletier, Daniel F Schmidt, and Weber. 2020.
Inceptiontime: Finding alexnet for time series classification. Data Mining and Knowledge Discovery 34, 6 (2020),
1936‚Äì1962.
Jana Iyengar and Martin Thomson. 2021. QUIC: A UDP-Based Multiplexed and Secure Transport. RFC 9000.
https://doi.org/10.17487/RFC9000
Saadat Izadi, Ahmadi, and Mahmood. 2022a. Network traffic classification using convolutional neural network and
ant-lion optimization. Computers and Electrical Engineering 101 (2022), 108024.
Saadat Izadi, Mahmood Ahmadi, and Rajabzadeh. 2022b. Network traffic classification using deep learning networks
and Bayesian data fusion. Journal of Network and Systems Management 30, 2 (2022), 25.
Mehak Khan, Hongzhi Wang, and Alladoumbaye Ngueilbaye. 2021. Attention-based deep gated fully convolutional
end-to-end architectures for time series classification. Neural Processing Letters 53, 3 (2021), 1995‚Äì2028.
Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 (2014).
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural
networks. Advances in neural information processing systems 25 (2012).
Mirja Kuhlewind and Brian Trammell. 2022. Applicability of the QUIC Transport Protocol. RFC 9308. ¬® https:
//doi.org/10.17487/RFC9308
Tsung-Yi Lin, Priya Goyal, and Girshick. 2017. Focal loss for dense object detection. In IEEE international conference
on computer vision. IEEE, 2980‚Äì2988.
Mohammad Lotfollahi and Jafari Siavoshani. 2020. Deep packet: A novel approach for encrypted traffic classification
using deep learning. Soft Computing 24, 3 (2020), 1999‚Äì2012.
Jan Luxemburk, Karel Hynek, and Cejka. 2023a. CESNET-QUIC22: A large one-month QUIC network traffic dataset Àá
from backbone lines. Data in Brief 46 (2023), 108888.
Jan Luxemburk, Karel Hynek, and Toma¬¥sÀá Cejka. 2023b. Encrypted traffic classification: the QUIC case. In Àá 2023 7th
Network Traffic Measurement and Analysis Conference (TMA). IEEE, 1‚Äì10.
Kiran Maharana, Surajit Mondal, and Bhushankumar Nemade. 2022. A review: Data pre-processing and data augmentation techniques. Global Transitions Proceedings 3, 1 (2022), 91‚Äì99.
Fannia Pacheco, Ernesto Exposito, and Mathieu Gineste. 2020. A framework to classify heterogeneous Internet traffic
with Machine Learning and Deep Learning techniques for satellite communications. Computer Networks 173
(2020), 107213.
SGOPAL Patro and Kishore Kumar Sahu. 2015. Normalization: A preprocessing stage. arXiv preprint
arXiv:1503.06462 (2015).
14
Preprint
Jason DM Rennie and Nathan Srebro. 2005. Loss functions for preference levels: Regression with discrete ordered
labels. In IJCAI multidisciplinary workshop, Vol. 1. AAAI Press, Menlo Park, CA.
Shahbaz Rezaei and Xin Liu. 2020. Multitask learning for network traffic classification. In 2020 29th ICCCN. IEEE,
1‚Äì9.
Raffaello Secchi and Cassara. 2022. Exploring Machine Learning for Classification of QUIC Flows over Satellite. In `
ICC 2022 ICC. IEEE, 4709‚Äì4714.
Robert J. Shahla, Reuven Cohen, and Friedman Roy. 2024. TrafficGrinder: A 0-RTT-Aware QUIC Load Balancer. In
2024 IEEE 32st International Conference on Network Protocols (ICNP). IEEE.
Tal Shapira and Yuval Shavitt. 2019. Flowpic: Encrypted internet traffic classification is as easy as image recognition.
In IEEE 2019 INFOCOM WKSHPS). IEEE, 680‚Äì687.
Guang-Lu Sun, Yibo Xue, and Dong. 2010. An novel hybrid method for effectively classifying encrypted traffic. In
2010 GLOBECOM. IEEE, 1‚Äì5.
Junjiao Tian, Niluthpol Chowdhury Mithun, and Seymour. 2020. Recall loss for imbalanced image classification and
semantic segmentation. Neural processing letters (2020).
Van Tong and Hai Anh Tran. 2018. A novel QUIC traffic classifier based on convolutional neural networks. In 2018
GLOBECOM. IEEE, IEEE, 1‚Äì6.
Md Shamim Towhid and Nashid Shahriar. 2022. Encrypted network traffic classification using self-supervised learning. In 2022 NetSoft. IEEE, 366‚Äì374.
Ashish Vaswani, Noam Shazeer, and Parmar. 2017. Attention is all you need. Advances in neural information processing systems 30, 8 (2017), 10.
Petr Velan, Milan Cerm Àá ak, and ¬¥ Celeda. 2015. A survey of methods for encrypted traffic classification and analysis. Àá
International Journal of Network Management 25, 5 (2015), 355‚Äì374.
Pan Wang, Feng Ye, Xuejiao Chen, and Yi Qian. 2018. Datanet: Deep learning based encrypted network traffic
classification in sdn home gateway. IEEE Access 6 (2018), 55380‚Äì55391.
Qi Wang, Yue Ma, Kun Zhao, and Yingjie Tian. 2020. A comprehensive survey of loss functions in machine learning.
Annals of Data Science (2020), 1‚Äì26.
A Appendices
Table 5: ùëá = 0.1-second window dataset: Images per class value, per server.
Class youtube.com semrush.com discord.com instagram.com mercedes-benz.com bleacherreport.com nicelocal.com facebook.com pcmag.com logitech.com google.com cdnetworks.com independent.co.uk cloudflare.com jetbrains.com
0 68,730 113,947 190,942 10,340 4,255 421,728 113,581 9,345 996,908 14,435 37,501 40,332 126,199 417,474 10,993
1 32,180 137,842 156,369 2,958 1,154 190,606 103,038 4,503 141,714 14,785 18,567 50,600 37,183 506,356 5,392
2 13,426 53,672 126,360 1,215 661 39,619 119,751 2,219 29,480 9,181 7,584 39,329 6,004 192,943 4,285
3 7,961 32,087 63,141 621 523 19,860 71,226 1,374 4,330 4,206 4,637 21,876 1,890 120,638 2,202
4 5,733 23,880 37,571 314 449 33,013 42,885 922 2,996 5,166 3,899 14,017 1,138 54,700 1,579
5 9,184 17,406 21,260 359 442 20,144 28,455 349 2,145 1,620 2,484 8,940 811 33,681 1,692
6 1,210 10,376 8,374 472 443 14,649 18,191 545 2,429 1,238 1,576 6,523 1,129 16,264 1,811
7 751 7,981 5,235 338 281 9,473 16,304 4,143 1,788 719 1,572 4,522 522 3,397 1,154
8 488 7,624 3,342 171 339 17,508 12,342 326 813 338 998 3,417 383 987 1,616
9 111 7,292 2,757 140 237 3,735 11,027 324 339 417 493 2,421 290 326 2,635
10 39 8,132 2,251 66 209 7,510 10,050 383 213 348 345 2,040 240 195 745
11 14 8,308 1,143 9 171 2,587 5,406 275 249 370 297 1,847 171 165 764
12 9 5,557 1,264 0 145 272 2,861 289 84 801 261 1,706 163 98 66
13 11 5,109 768 0 129 230 1,397 332 148 462 200 1,569 123 113 0
14 7 4,211 683 0 151 270 736 136 8 717 218 1,289 108 80 0
15 4 4,964 685 0 91 184 342 313 5 464 146 1,415 109 96 0
16 6 6,328 318 0 68 201 123 48 41 473 169 1,437 68 74 0
17 8 6,029 311 0 83 176 125 55 18 441 99 1,229 64 55 0
18 4 5,442 348 0 83 73 87 26 21 221 77 1,014 65 41 0
19 8 4,797 271 0 40 47 31 56 8 211 76 998 38 16 0
20 5 3,732 430 0 33 30 23 36 1 141 44 1,152 42 26 0
Sum 139,889 474,716 623,823 17,003 9,987 781,915 557,981 25,999 1,183,738 56,754 81,243 207,673 176,740 1,347,725 34,934
15
Preprint
Table 6: ùëá = 0.3-second window dataset: Images per class value, per server.
Class youtube.com semrush.com discord.com instagram.com mercedes-benz.com bleacherreport.com nicelocal.com facebook.com pcmag.com logitech.com google.com cdnetworks.com independent.co.uk cloudflare.com jetbrains.com
0 11,185 23,751 26,130 2,942 1,082 107,871 19,851 1,537 316,252 3,990 7,031 8,530 31,494 45,521 3,100
1 12,954 56,849 22,566 1,081 214 70,024 21,724 1,510 35,476 5,041 6,702 13,318 26,392 86,815 1,713
2 6,569 34,403 31,911 655 168 37,090 23,963 640 21,239 4,459 4,465 11,463 4,968 84,493 1,622
3 4,651 18,272 33,139 359 105 18,401 23,611 917 5,272 2,663 1,954 7,993 2,075 37,014 1,005
4 3,447 13,116 33,214 286 78 11,685 18,049 768 1,427 2,261 1,617 7,114 928 22,280 722
5 6,307 12,567 23,249 143 71 7,682 15,305 312 768 1,629 912 6,084 491 14,270 732
6 3,745 7,098 17,279 237 88 6,711 12,300 167 1,077 2,182 860 5,844 292 13,965 741
7 2,918 5,823 18,919 541 67 8,433 9,786 2,254 1,114 739 1,293 5,140 363 12,478 532
8 1,439 4,921 13,591 238 76 22,045 8,065 193 1,047 511 979 4,414 246 10,979 1,025
9 815 3,624 4,322 189 71 12,548 7,170 63 468 477 529 3,350 153 7,975 1,642
10 230 3,917 2,848 190 78 13,965 7,394 69 358 342 370 2,717 117 2,784 1,505
11 166 5,221 1,651 167 62 10,530 7,527 61 551 335 396 2,024 173 954 2,383
12 80 4,704 1,261 77 50 2,464 8,338 114 267 360 373 1,754 103 641 1,677
13 46 3,430 882 7 50 478 9,361 185 103 289 317 1,336 125 443 71
14 24 2,194 988 0 66 248 10,034 713 169 982 274 1,055 110 290 0
15 29 2,725 775 0 71 341 7,660 293 75 549 273 909 133 152 0
16 14 3,827 669 0 62 232 5,217 192 25 444 188 752 58 125 0
17 10 4,288 431 0 60 369 3,471 185 33 516 169 626 51 88 0
18 10 3,641 479 0 75 170 2,207 356 50 387 152 469 71 93 0
19 11 3,300 408 0 77 104 1,177 424 14 262 132 375 78 80 0
20 9 3,806 536 0 69 139 759 35 12 162 82 440 59 48 0
Sum 54,659 221,477 235,248 7,112 2,740 331,530 222,969 10,988 385,797 28,580 29,068 85,707 68,480 341,488 18,470
16